{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_jobs=2\n"
     ]
    }
   ],
   "source": [
    "# Setup parameters for experiment\n",
    "data_name = 'concentric_circles'\n",
    "n_train = 1000\n",
    "cv = 3  # Number of cv splits\n",
    "random_state = 0\n",
    "\n",
    "import multiprocessing\n",
    "n_jobs = multiprocessing.cpu_count()\n",
    "print('n_jobs=%d' % n_jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports and basic setup of logging and seaborn\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "import sys, os, logging\n",
    "import pickle\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.base import clone\n",
    "from sklearn.externals.joblib import Parallel, delayed\n",
    "from sklearn.utils import check_random_state\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "sys.path.append('..')  # Enable importing from package ddl without installing ddl\n",
    "from ddl.datasets import make_toy_data\n",
    "from ddl.deep import DeepDestructorCV, CompositeDestructor\n",
    "from ddl.independent import IndependentDestructor, IndependentDensity, IndependentInverseCdf\n",
    "from ddl.univariate import ScipyUnivariateDensity, HistogramUnivariateDensity\n",
    "from ddl.linear import (LinearProjector, RandomOrthogonalEstimator, \n",
    "                        BestLinearReconstructionDestructor)\n",
    "from ddl.autoregressive import AutoregressiveDestructor\n",
    "from ddl.mixture import GaussianMixtureDensity, FirstFixedGaussianMixtureDensity\n",
    "from ddl.tree import TreeDestructor, TreeDensity, RandomTreeEstimator\n",
    "from ddl.externals.mlpack import MlpackDensityTreeEstimator\n",
    "\n",
    "# Setup seaborn\n",
    "try:\n",
    "    import seaborn as sns\n",
    "except ImportError:\n",
    "    print('Could not import seaborn so colors may be different') \n",
    "else:\n",
    "    sns.set()\n",
    "    sns.despine()\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(stream=sys.stdout)\n",
    "logging.captureWarnings(True)\n",
    "logging.getLogger('ddl').setLevel(logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BASELINE SHALLOW DESTRUCTORS\n",
    "gaussian_full = CompositeDestructor(\n",
    "    destructors=[\n",
    "        LinearProjector(\n",
    "            linear_estimator=PCA(),\n",
    "            orthogonal=False,\n",
    "        ),\n",
    "        IndependentDestructor(),\n",
    "    ],\n",
    ")\n",
    "mixture_20 = AutoregressiveDestructor(\n",
    "    density_estimator=GaussianMixtureDensity(\n",
    "        covariance_type='spherical',\n",
    "        n_components=20,\n",
    "    )\n",
    ")\n",
    "random_tree = CompositeDestructor(\n",
    "    destructors=[\n",
    "        IndependentDestructor(),\n",
    "        TreeDestructor(\n",
    "            tree_density=TreeDensity(\n",
    "                tree_estimator=RandomTreeEstimator(min_samples_leaf=20, max_leaf_nodes=50),\n",
    "                node_destructor=IndependentDestructor(\n",
    "                    independent_density=IndependentDensity(\n",
    "                        univariate_estimators=HistogramUnivariateDensity(\n",
    "                            bins=10, alpha=10, bounds=[0,1]\n",
    "                        )\n",
    "                    )\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "density_tree = CompositeDestructor(\n",
    "    destructors=[\n",
    "        IndependentDestructor(),\n",
    "        TreeDestructor(\n",
    "            tree_density=TreeDensity(\n",
    "                tree_estimator=MlpackDensityTreeEstimator(min_samples_leaf=10),\n",
    "                uniform_weight=0.001,\n",
    "            )\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "baseline_destructors = [gaussian_full, mixture_20, random_tree, density_tree]\n",
    "baseline_names = ['Gaussian', 'Mixture', 'SingleRandTree', 'SingleDensityTree']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LINEAR DESTRUCTORS\n",
    "alpha_histogram = [1, 10, 100]\n",
    "random_linear_projector = LinearProjector(\n",
    "    linear_estimator=RandomOrthogonalEstimator(), orthogonal=True\n",
    ")\n",
    "canonical_histogram_destructors = [\n",
    "    IndependentDestructor(\n",
    "        independent_density=IndependentDensity(\n",
    "            univariate_estimators=HistogramUnivariateDensity(bins=20, bounds=[0, 1], alpha=a)\n",
    "        )\n",
    "    )\n",
    "    for a in alpha_histogram\n",
    "]\n",
    "linear_destructors = [\n",
    "    DeepDestructorCV(\n",
    "        init_destructor=IndependentDestructor(),\n",
    "        canonical_destructor=CompositeDestructor(destructors=[\n",
    "            IndependentInverseCdf(),  # Project to inf real space\n",
    "            random_linear_projector,  # Random linear projector\n",
    "            IndependentDestructor(),  # Project to canonical space\n",
    "            destructor,  # Histogram destructor in canonical space\n",
    "        ]),\n",
    "        n_extend=20,  # Need to extend since random projections\n",
    "    )\n",
    "    for destructor in canonical_histogram_destructors\n",
    "]\n",
    "linear_names = ['RandLin (%g)' % a for a in alpha_histogram]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tree_names' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-755358f9457d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mn_extend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     )\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mdestructor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmixture_destructors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtree_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m ]\n\u001b[1;32m     26\u001b[0m \u001b[0mmixture_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'GausMix (%.2g)'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfixed_weight\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tree_names' is not defined"
     ]
    }
   ],
   "source": [
    "# MIXTURE DESTRUCTORS\n",
    "fixed_weight = [0.1, 0.5, 0.9]\n",
    "mixture_destructors = [\n",
    "    CompositeDestructor(destructors=[\n",
    "        IndependentInverseCdf(),\n",
    "        AutoregressiveDestructor(\n",
    "            density_estimator=FirstFixedGaussianMixtureDensity(\n",
    "                covariance_type='spherical',\n",
    "                n_components=20,\n",
    "                fixed_weight=w,\n",
    "            )\n",
    "        )\n",
    "    ])\n",
    "    for w in fixed_weight \n",
    "]\n",
    "# Make deep destructors\n",
    "mixture_destructors = [\n",
    "    DeepDestructorCV(\n",
    "        init_destructor=IndependentDestructor(),\n",
    "        canonical_destructor=destructor,\n",
    "        n_extend=5, \n",
    "    )\n",
    "    for destructor in mixture_destructors\n",
    "]\n",
    "mixture_names = ['GausMix (%.2g)' % w for w in fixed_weight]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TREE DESTRUCTORS\n",
    "# Random trees\n",
    "histogram_alpha = [1, 10, 100]\n",
    "tree_destructors = [\n",
    "    TreeDestructor(\n",
    "        tree_density=TreeDensity(\n",
    "            tree_estimator=RandomTreeEstimator(\n",
    "                max_leaf_nodes=4\n",
    "            ),\n",
    "            node_destructor=IndependentDestructor(\n",
    "                independent_density=IndependentDensity(\n",
    "                    univariate_estimators=HistogramUnivariateDensity(\n",
    "                        alpha=a, bins=10, bounds=[0,1]\n",
    "                    )\n",
    "                )\n",
    "            ),\n",
    "        )\n",
    "    )\n",
    "    for a in histogram_alpha\n",
    "]\n",
    "tree_names = ['RandTree (%g)' % a for a in histogram_alpha]\n",
    "\n",
    "# Density trees using mlpack\n",
    "tree_uniform_weight = [0.1, 0.5, 0.9]\n",
    "tree_destructors.extend([\n",
    "    TreeDestructor(\n",
    "        tree_density=TreeDensity(\n",
    "            tree_estimator=MlpackDensityTreeEstimator(min_samples_leaf=10),\n",
    "            uniform_weight=w,\n",
    "        )\n",
    "    )\n",
    "    for w in tree_uniform_weight\n",
    "])\n",
    "tree_names.extend(['DensityTree (%.2g)' % w for w in tree_uniform_weight])\n",
    "\n",
    "# Add random rotation to tree destructors\n",
    "tree_destructors = [\n",
    "    CompositeDestructor(destructors=[\n",
    "        IndependentInverseCdf(),\n",
    "        LinearProjector(linear_estimator=RandomOrthogonalEstimator()),\n",
    "        IndependentDestructor(),\n",
    "        destructor,\n",
    "    ])\n",
    "    for destructor in tree_destructors\n",
    "]\n",
    "\n",
    "# Make deep destructors\n",
    "tree_destructors = [\n",
    "    DeepDestructorCV(\n",
    "        init_destructor=IndependentDestructor(),\n",
    "        canonical_destructor=destructor,\n",
    "        # Density trees don't need to extend as much as random trees\n",
    "        n_extend=50 if 'Rand' in name else 5, \n",
    "    )\n",
    "    for destructor, name in zip(tree_destructors, tree_names)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make dataset and create train/test splits\n",
    "n_samples = 2 * n_train\n",
    "D = make_toy_data(data_name, n_samples=n_samples, random_state=random_state)\n",
    "X_train = D.X[:n_train]\n",
    "y_train = D.y[:n_train] if D.y is not None else None\n",
    "X_test = D.X[n_train:]\n",
    "y_test = D.y[n_train:] if D.y is not None else None\n",
    "\n",
    "def _fit_and_score(data_name, destructor, destructor_name, n_train, random_state=0):\n",
    "    \"\"\"Simple function to fit and score a destructor.\"\"\"\n",
    "    # Fix random state of global generator so repeatable if destructors are random\n",
    "    rng = check_random_state(random_state)\n",
    "    old_random_state = np.random.get_state()\n",
    "    np.random.seed(rng.randint(2 ** 32, dtype=np.uint32))\n",
    "    \n",
    "    # Fit destructor\n",
    "    start_time = time.time()\n",
    "    destructor.fit(X_train)\n",
    "    train_time = time.time() - start_time\n",
    "    \n",
    "    # Get scores\n",
    "    start_time = time.time()\n",
    "    train_score = destructor.score(X_train)\n",
    "    test_score = destructor.score(X_test)\n",
    "    score_time = time.time() - start_time\n",
    "    logger.debug('train=%.3f, test=%.3f, train_time=%.3f, score_time=%.3f, destructor=%s, data_name=%s' \n",
    "                 % (train_score, test_score, train_time, score_time, destructor_name, data_name))\n",
    "\n",
    "    # Reset random state\n",
    "    np.random.set_state(old_random_state)\n",
    "    return dict(fitted_destructor=destructor,\n",
    "                destructor_name=destructor_name,\n",
    "                train_score=train_score,\n",
    "                test_score=test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Collect all destructors and set CV parameter\n",
    "destructors = baseline_destructors + linear_destructors + mixture_destructors + tree_destructors\n",
    "destructor_names = baseline_names + linear_names  + mixture_names + tree_names\n",
    "for d in destructors:\n",
    "    if 'cv' in d.get_params():\n",
    "        d.set_params(cv=cv)\n",
    "        \n",
    "# Fit and score destructor\n",
    "results_arr = Parallel(n_jobs=n_jobs)(\n",
    "    delayed(_fit_and_score)(\n",
    "        data_name, destructor, destructor_name, n_train, random_state=random_state,\n",
    "    )\n",
    "    for di, (destructor, destructor_name) in enumerate(zip(destructors, destructor_names))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Compile results for plotting\n",
    "def _add_val_over_bar(ax, vals, fmt='%.2g'):\n",
    "    \"\"\"Add value text over matplotlib bar chart.\"\"\"\n",
    "    for v, p in zip(vals, ax.patches):\n",
    "        height = p.get_height()\n",
    "        ax.text(p.get_x() + p.get_width() / 2.0, height + p.get_height() * 0.02,\n",
    "                fmt % v, ha='center', fontsize=8)\n",
    "        \n",
    "# Get scores, number of layers and destructor names\n",
    "exp_test_scores = np.exp([res['test_score'] for res in results_arr])\n",
    "n_layers=np.array([\n",
    "    res['fitted_destructor'].best_n_layers_ \n",
    "    if hasattr(res['fitted_destructor'], 'best_n_layers_') else 1\n",
    "    for res in results_arr\n",
    "])\n",
    "labels = [name for _, name in destructors_with_names]\n",
    "x_bar = np.arange(len(labels))\n",
    "\n",
    "# Show result plot\n",
    "figsize = 8 * np.array([1, 1]) * np.array([len(labels) / 16.0, 0.5])\n",
    "fig, axes = plt.subplots(2, 1, figsize=figsize, dpi=300, sharex='col', \n",
    "                         gridspec_kw=dict(height_ratios=[3, 1]))\n",
    "axes[0].bar(x_bar, exp_test_scores, color=sns.color_palette()[0])\n",
    "axes[0].set_ylabel('Geom. Mean Likelihood')\n",
    "axes[0].set_title('%s Dataset' % data_name.replace('_', ' ').title())\n",
    "_add_val_over_bar(axes[0], exp_test_scores)\n",
    "axes[1].bar(x_bar, n_layers, color=sns.color_palette()[1])\n",
    "axes[1].set_ylabel('# of Layers')\n",
    "_add_val_over_bar(axes[1], n_layers, fmt='%d')\n",
    "\n",
    "# Rotate tick labels\n",
    "plt.xticks(x_bar, ['%s' % l for l in labels])\n",
    "for item in plt.gca().get_xticklabels():\n",
    "    item.set_rotation(30)\n",
    "    item.set_horizontalalignment('right')\n",
    "\n",
    "# Uncomment below to save png images into notebook folder\n",
    "#plt.savefig('bar_%s.png' % D.name, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select best destructors of main groups (linear, mixture, tree) and precompute transforms for figure below\n",
    "selected_arr = [\n",
    "    res for res in results_arr if res['destructor_name'] in [\n",
    "        'RandLin (100)', 'GausMix (0.5)', 'DensityTree (0.9)'\n",
    "    ]\n",
    "]\n",
    "def _add_transform(res):\n",
    "    res['Z_train'] = res['fitted_destructor'].transform(X_train)\n",
    "    res['Z_test'] = res['fitted_destructor'].transform(X_test)\n",
    "    return res\n",
    "selected_arr = [_add_transform(res) for res in selected_arr] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Create figure for destroyed samples (train and test)\n",
    "def _clean_axis(ax, limits=None):\n",
    "    if limits is not None:\n",
    "        for i, lim in enumerate(limits):\n",
    "            eps = 0.01 * (lim[1] - lim[0])\n",
    "            lim = [lim[0] - eps, lim[1] + eps]\n",
    "            if i == 0:\n",
    "                ax.set_xlim(lim)\n",
    "            else:\n",
    "                ax.set_ylim(lim)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    ax.set_aspect('equal', 'box')\n",
    "    \n",
    "def _scatter_X_y(X, y, ax, **kwargs):\n",
    "    if 's' not in kwargs:\n",
    "        kwargs['s'] = 18\n",
    "    if y is not None:\n",
    "        for label in np.unique(y):\n",
    "            ax.scatter(X[y == label, 0], X[y == label, 1], **kwargs)\n",
    "    else:\n",
    "        ax.scatter(X[:, 0], X[:, 1])\n",
    "        \n",
    "fig, axes_arr = plt.subplots(1, len(selected_arr) * 2, figsize=(20, 4))\n",
    "axes_mat = axes_arr.reshape(-1, 2)\n",
    "for res, axes in zip(selected_arr, axes_mat):\n",
    "    for split, X_split, y_split,  ax in zip(\n",
    "        ['Train', 'Test'], [X_train, X_test], [y_train, y_test], axes\n",
    "    ):\n",
    "        _scatter_X_y(res['Z_%s' % split.lower()], y_split, ax)\n",
    "        _clean_axis(ax, limits=[[0, 1], [0, 1]])\n",
    "        ax.set_title('%s %s' % (res['destructor_name'], split), fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create figure to show progression across stages\n",
    "selected_res = next(res for res in results_arr if res['destructor_name'] == 'DensityTree (0.9)')\n",
    "selected_destructor = selected_res['fitted_destructor']\n",
    "n_layers = len(selected_destructor.fitted_destructors_)\n",
    "disp_layers = np.minimum(n_layers - 1, np.logspace(0, np.log10(n_layers + 1), 4, dtype=np.int) - 1)\n",
    "\n",
    "fig, axes = plt.subplots(2, len(disp_layers), figsize=np.array([11, 6]))\n",
    "axes = axes.transpose()\n",
    "for li, axes_col in zip(disp_layers, axes):\n",
    "    partial_idx = np.arange(li + 1)\n",
    "    Z_partial_train = selected_destructor.transform(X_train, partial_idx=partial_idx)\n",
    "    \n",
    "    # Create grid of points (extend slightly beyond min and maximum of data)\n",
    "    n_query = 100\n",
    "    perc_extend = 0.02\n",
    "    bounds = np.array([np.min(D.X, axis=0), np.max(D.X, axis=0)]).transpose()\n",
    "    bounds_diff = bounds[:, 1] - bounds[:, 0]\n",
    "    bounds[:, 0] -= perc_extend / 2 * bounds_diff\n",
    "    bounds[:, 1] += perc_extend / 2 * bounds_diff\n",
    "    x_q = np.linspace(*bounds[0, :], num=n_query)\n",
    "    y_q = np.linspace(*bounds[1, :], num=n_query)\n",
    "    X_grid, Y_grid = np.meshgrid(x_q, y_q)\n",
    "    X_query = np.array([X_grid.ravel(), Y_grid.ravel()]).transpose()\n",
    "    \n",
    "    # Get density values along grid\n",
    "    log_pdf_grid = selected_destructor.score_samples(\n",
    "        X_query, partial_idx=partial_idx).reshape(n_query, -1)\n",
    "    pdf_grid = np.exp(np.maximum(log_pdf_grid, -16))\n",
    "    \n",
    "    # Show scatter plot\n",
    "    _scatter_X_y(Z_partial_train, y_train, axes_col[0], s=10)\n",
    "    _clean_axis(axes_col[0], limits=[[0, 1], [0, 1]])\n",
    "    axes_col[0].set_title('Layer %d: Train Data' % (li+1))\n",
    "    \n",
    "    # Show density\n",
    "    axes_col[1].pcolormesh(X_grid, Y_grid, -pdf_grid, cmap='gray', zorder=-1)\n",
    "    _clean_axis(axes_col[1])\n",
    "    axes_col[1].set_title('Layer %d: Implicit Dens.' % (li+1))\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
